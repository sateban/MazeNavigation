{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] starting to read a webcam ...\n",
      "60\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 100\u001b[0m\n\u001b[0;32m     96\u001b[0m curWindow \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mint\u001b[39m(left), \u001b[38;5;28mint\u001b[39m(top), \u001b[38;5;28mint\u001b[39m(right \u001b[38;5;241m-\u001b[39m left),\n\u001b[0;32m     97\u001b[0m \t\t\t \u001b[38;5;28mint\u001b[39m(bottom \u001b[38;5;241m-\u001b[39m top) )\n\u001b[0;32m     99\u001b[0m \u001b[38;5;66;03m# intialize the CAMShift Tracker\u001b[39;00m\n\u001b[1;32m--> 100\u001b[0m camShifTracker \u001b[38;5;241m=\u001b[39m \u001b[43mCAMShiftTracker\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbbox\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    102\u001b[0m boolDetectinfirsFrameOnly \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28;01mcontinue\u001b[39;00m \n",
      "File \u001b[1;32mc:\\Users\\Jake\\Documents\\Workspace\\Projects\\Mapua\\Maze Navigating Robot using Lucas-Kanade Optical Flow Method with Coarse-to-Fine Algorithm\\trackers\\camshifttracker.py:22\u001b[0m, in \u001b[0;36mCAMShiftTracker.__init__\u001b[1;34m(self, curWindowRoi, imgBGR)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;124;03mcurWindow =[x,y, w,h] // initialize the window to be tracked by the tracker \u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdateCurrentWindow(curWindowRoi)\n\u001b[1;32m---> 22\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdateHistograms\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimgBGR\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# set up the termination criteria for meanshift, either 10 iterations or move by at least 1 pt\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mterm_criteria \u001b[38;5;241m=\u001b[39m (cv2\u001b[38;5;241m.\u001b[39mTERM_CRITERIA_EPS \u001b[38;5;241m|\u001b[39m cv2\u001b[38;5;241m.\u001b[39mTERM_CRITERIA_COUNT, \u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Jake\\Documents\\Workspace\\Projects\\Mapua\\Maze Navigating Robot using Lucas-Kanade Optical Flow Method with Coarse-to-Fine Algorithm\\trackers\\camshifttracker.py:41\u001b[0m, in \u001b[0;36mCAMShiftTracker.updateHistograms\u001b[1;34m(self, imgBGR)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdateHistograms\u001b[39m(\u001b[38;5;28mself\u001b[39m, imgBGR):\n\u001b[0;32m     34\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;124;03m      update the histogram and rois according to the current object in the current image\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;124;03m    \u001b[39;00m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[1;32m---> 41\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbgrObjectRoi \u001b[38;5;241m=\u001b[39m imgBGR[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurWindow[\u001b[38;5;241m1\u001b[39m]: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurWindow[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurWindow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m,\n\u001b[0;32m     42\u001b[0m                             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurWindow[\u001b[38;5;241m0\u001b[39m]: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurWindow[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurWindow[\u001b[38;5;241m2\u001b[39m]]\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhsvObjectRoi \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbgrObjectRoi, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2HSV)\n\u001b[0;32m     45\u001b[0m     \u001b[38;5;66;03m# get the mask for calculating histogram and also remove some noise\u001b[39;00m\n",
      "\u001b[1;31mIndexError\u001b[0m: tuple index out of range"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "'''\n",
    "Created on Sep 9, 2017\n",
    "\n",
    "@author: inayat\n",
    "'''\n",
    "\n",
    "# import the required  packages\n",
    "from imutils.video import WebcamVideoStream\n",
    "#from imutils.video import FPS\n",
    "import numpy as np\n",
    "import argparse\n",
    "import imutils\n",
    "import time\n",
    "import cv2\n",
    "\n",
    "import dlib\n",
    "\n",
    "from trackers.camshifttracker import CAMShiftTracker\n",
    "\t\n",
    "if __name__ == '__main__':\n",
    "\tprint(\"[info] starting to read a webcam ...\")\n",
    "\t\n",
    "\t# Video File\n",
    "\tvid_path = './resources/maze/with_obstacle.mp4'\n",
    "\t# vid_path = './resources/videos/boy-walking.mp4'\n",
    "\n",
    "\t# Set Video Source (Camera / Video File)\n",
    "\t# cap = cv2.VideoCapture(0) # Camera -> use index 0 for default/builtin camera\n",
    "\tcapWebCam = cv2.VideoCapture(vid_path) # Video File\n",
    "\t# capWebCam = WebcamVideoStream(1).start()\n",
    "\t# time.sleep(1.0)\n",
    "\t\n",
    "\tret, roiFrame = capWebCam.read()\n",
    "\n",
    "\tcv2.imshow(\"Select ROI\", roiFrame)\n",
    "\troi = cv2.selectROI(\"Select ROI\", roiFrame, fromCenter=False, showCrosshair=True)\n",
    "\n",
    "\t# initialize dlib face detector\n",
    "\t\n",
    "\t# frontFaceDetector = dlib.get_frontal_face_detector() \n",
    "\t\n",
    "\t\n",
    "\t# meanShift tracker\n",
    "\t\n",
    "\tcamShifTracker = None\n",
    "\t\n",
    "\tcurWindow = None\n",
    "\t\n",
    "\t# start the frame per second  (FPS) counter\n",
    "\t#fps = FPS2().start() \n",
    "\t\n",
    "\tboolDetectinfirsFrameOnly = True\n",
    "\t\n",
    "\t# loop over the frames obtained from the webcam\n",
    "\twhile True:\n",
    "\t\t# grab each frame from the threaded  stream,\n",
    "\t\t# resize\n",
    "\t\t# it, and convert it to grayscale (while still retaining 3\n",
    "\t\t# channels)\n",
    "\t\tisFrameFound, frame1 = capWebCam.read()\n",
    "\n",
    "\t\tif not isFrameFound:\n",
    "\t\t\tprint(\"No Frame\")\n",
    "\t\t\tbreak\n",
    "\n",
    "\t\t# frame = cv2.flip(frame1,1)\n",
    "\t\tframe = frame1 #cv2.flip(frame1,1)\n",
    "\t\t\n",
    "\t\t#frame = imutils.resize(frame, width=450)\n",
    "\t\t#frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\t\t#frame = np.dstack([frame, frame, frame])\n",
    "\t\t\n",
    "\t\t# display the size of the queue on the frame\n",
    "\t\t#cv2.putText(frame, \"Queue Size: {}\".format(fvs.Q.qsize()),\n",
    "\t\t#            (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "\t\t\n",
    "\t\t\n",
    "\t\tif boolDetectinfirsFrameOnly:\n",
    "\t\t\t\n",
    "\t\t\t# start the frame per second  (FPS) counter\n",
    "\t\t\t# bbox = [(16, 157), (86, 238)]\n",
    "\t\t\tbbox = [(roi[0], roi[1]), (roi[2], roi[3])]\n",
    "\t\t\t# bbox = (roi[0], roi[1]), (roi[2], roi[3])\n",
    "\t\t\t# print(bbox)\n",
    "\t\t\t\t\t\t\n",
    "\t\t\t# convert dlib rect to opencv rect\n",
    "\t\t\tleft = min(bbox[0][0], bbox[1][0])\n",
    "\t\t\ttop = min(bbox[0][1], bbox[1][1])\n",
    "\t\t\tright = max(bbox[0][0], bbox[1][0])\n",
    "\t\t\tbottom = max(bbox[0][1], bbox[1][1])\n",
    "\n",
    "\t\t\tprint(left)\n",
    "\t\t\t\n",
    "\t\t\t# curWindow = (int(bbox.left()), int(bbox.top()), int(bbox.right() - bbox.left()),\n",
    "\t\t\t# \t\t\t int(bbox.bottom() - bbox.top()) )\n",
    "\t\t\tcurWindow = (int(left), int(top), int(right - left),\n",
    "\t\t\t\t\t\t int(bottom - top) )\n",
    "\t\t\t\n",
    "\t\t\tprint(curWindow)\n",
    "\t\t\t\n",
    "\t\t\t# intialize the CAMShift Tracker\n",
    "\t\t\tcamShifTracker = CAMShiftTracker(curWindow, frame)\n",
    "\t\t\t\n",
    "\t\t\tboolDetectinfirsFrameOnly = False\n",
    "\t\t\t\n",
    "\t\t\tcontinue \n",
    "\t\t\n",
    "\t\tcamShifTracker.computeNewWindow(frame)\n",
    "\t\t\n",
    "\t\tx,y, w, h = camShifTracker.getCurWindow()\n",
    "\t\t\n",
    "\t\tbkprojectImage = camShifTracker.getBackProjectedImage(frame)\n",
    "\t\t\n",
    "\t\tcv2.imshow(\"CAMShift Face in Back Project Image\", bkprojectImage)\n",
    "\t\t\n",
    "\t\t# display the current window \n",
    "\t\tcv2.rectangle(frame, (x,y), (x+w, y+h), (255, 0, 0), 2, cv2.LINE_AA)\n",
    "\t\t\n",
    "\t\trotatedWindow = camShifTracker.getRotatedWindow()\n",
    "\t\t#display rotated window\n",
    "\t\tcv2.polylines(frame, [rotatedWindow], True, (0,255,0), 2, cv2.LINE_AA)\n",
    "\t\t   \n",
    "\t\t# cv2.putText(frame, \"FPS: {:.2f}\".format(fps.fps()),\n",
    "\t\t#             (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "\t\t\n",
    "\t\t# show the frame and update the FPS counter\n",
    "\t\tcv2.imshow(\"CAMShift Face Tracking\", frame)\n",
    "\t\t\n",
    "\t\tif cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "\t\t\tbreak\n",
    "\t\t\n",
    "\t# do a bit of cleanup\n",
    "\tcapWebCam.release()\n",
    "\tcv2.destroyAllWindows()\n",
    "\t\n",
    "\t"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
