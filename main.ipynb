{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nothing done.\n"
     ]
    }
   ],
   "source": [
    "%reset\n",
    "import ctypes\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "def get_screen_size():\n",
    "\tuser32 = ctypes.windll.user32\n",
    "\tscreensize = (user32.GetSystemMetrics(0), user32.GetSystemMetrics(1))\n",
    "\treturn screensize\n",
    "\n",
    "lk_params = dict(winSize=(15, 15),\n",
    "\t\t\t\t maxLevel=10,\n",
    "\t\t\t\t criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n",
    "\n",
    "feature_params = dict(maxCorners=20,\n",
    "\t\t\t\t\t  qualityLevel=0.3,\n",
    "\t\t\t\t\t  minDistance=10,\n",
    "\t\t\t\t\t  blockSize=7)\n",
    "\n",
    "trajectory_len = 40 # pixel/trajectories\n",
    "detect_interval = 5\n",
    "trajectories = []\n",
    "roi_trajectories = []\n",
    "object_max_search = 0\n",
    "frame_idx = 0\n",
    "\n",
    "# Video File\n",
    "vid_path = './resources/maze/with_obstacle.mp4'\n",
    "\n",
    "# Set Video Source (Camera / Video File)\n",
    "# cap = cv2.VideoCapture(0) # Camera -> use index 0 for default/builtin camera\n",
    "cap = cv2.VideoCapture(vid_path) # Video File\n",
    "\n",
    "while True:\n",
    "\tisFrameFound, frame = cap.read()\n",
    "\t\n",
    "\tif not isFrameFound:\n",
    "\t\tprint(\"No Frame\")\n",
    "\t\tbreak\n",
    "\n",
    "\tframe_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) # Convert Colored Frame to Gray Color since HOG feature/Canny needs a gray\n",
    "\tframe_canny = cv2.Canny(frame_gray, 100, 200) # Process Canny before plugging it to LK\n",
    "\tframe_lukas_kanade_tracker = frame #.copy()\n",
    "\n",
    "\t# Calculate optical flow for a sparse feature set using the iterative Lucas-Kanade Method\n",
    "\tif len(trajectories) > 0:\n",
    "\t\tprev_frame, current_frame = prev_gray, frame_canny\n",
    "\t\tinitial_points = np.float32([trajectory[-1] for trajectory in trajectories]).reshape(-1, 1, 2) # Pixel before endpoint\n",
    "\t\t\n",
    "\t\t# calcOpticalFlowPyrLK -> optical flow-based feature tracking algorithm\n",
    "\t\ttracked_points, status, error = cv2.calcOpticalFlowPyrLK(prev_frame, current_frame, initial_points, None, **lk_params)\n",
    "\t\tend_point, status, error = cv2.calcOpticalFlowPyrLK(current_frame, prev_frame, tracked_points, None, **lk_params)\n",
    "\t\tdisplacement = abs(initial_points - end_point).reshape(-1, 2).max(-1)\n",
    "\t\tgood = displacement < 1\n",
    "\n",
    "\t\tnew_trajectories = []\n",
    "\n",
    "\t\t# Get all the trajectories\n",
    "\t\tfor trajectory, (x, y), good_flag in zip(trajectories, tracked_points.reshape(-1, 2), good):\n",
    "\t\t\tif not good_flag:\n",
    "\t\t\t\tcontinue\n",
    "\t\t\ttrajectory.append((x, y))\n",
    "\t\t\tif len(trajectory) > trajectory_len:\n",
    "\t\t\t\tdel trajectory[0]\n",
    "\t\t\tnew_trajectories.append(trajectory)\n",
    "\n",
    "\t\t\tcv2.circle(frame_lukas_kanade_tracker, (int(x), int(y)), 2, (0, 0, 255), -1) # Red Dots at Upper Left Frame\n",
    "\n",
    "\t\ttrajectories = new_trajectories\n",
    "\n",
    "\t\t# Draw all the trajectories\n",
    "\t\tcv2.polylines(frame_lukas_kanade_tracker, [np.int32(trajectory) for trajectory in trajectories], False, (0, 255, 0))\n",
    "\t\tcv2.putText(frame_lukas_kanade_tracker, 'track counter: %d' % len(trajectories), (20, 80), cv2.FONT_HERSHEY_PLAIN, 1, (0, 255, 0), 2)\n",
    "\n",
    "\t# Update interval - When to update and detect new features\n",
    "\tif frame_idx % detect_interval == 0: # % modulo\n",
    "\t\tframe_lukas_kanade_goodfeat = np.zeros_like(frame_canny)\n",
    "\t\tframe_lukas_kanade_goodfeat[:] = 255\n",
    "\n",
    "\t\t# Lastest point in latest trajectory\n",
    "\t\tfor x, y in [np.int32(trajectory[-1]) for trajectory in trajectories]:\n",
    "\t\t\t# if object_max_search < y:\n",
    "\t\t\tcv2.circle(frame_lukas_kanade_goodfeat, (x, y), 3, 0, -1) # Desc: Dots in the Screen, Trackpoints, Black Dots (Upper Right Frame)\n",
    "\n",
    "\t\t# Detect the good features to track -> Lukas-Kanade\n",
    "\t\tp = cv2.goodFeaturesToTrack(frame_canny, mask=frame_lukas_kanade_goodfeat, **feature_params)\n",
    "\t\tif p is not None:\n",
    "\t\t\t# If good features can be tracked - add that to the trajectories\n",
    "\t\t\tfor x, y in np.float32(p).reshape(-1, 2):\n",
    "\t\t\t\ttrajectories.append([(x, y)]) # Trackers: History of previous optical flow\n",
    "\n",
    "\tframe_idx += 1\n",
    "\tprev_gray = frame_canny\n",
    "\n",
    "\t# █▀ █ █ █▀█ █ █ █   █▀█ █▄ █ █   █▄█   █   █▀█ █ █ █ █▀▀ █▀█   █   █▀▀ ▄▀█ █▀▄ █ █▄ █ █▀▀   █   █ █▄ █ █▀▀ █▀\n",
    "\t# ▄█ █▀█ █▄█ ▀▄▀▄▀   █▄█ █ ▀█ █▄▄  █    █▄▄ █▄█ ▀▄▀▄▀ ██▄ █▀▄   █▄▄ ██▄ █▀█ █▄▀ █ █ ▀█ █▄█   █▄▄ █ █ ▀█ ██▄ ▄█\n",
    "\tif frame_lukas_kanade_tracker.shape[2] == 3:\n",
    "\t\tframe_lukas_kanade_tracker = cv2.cvtColor(frame_lukas_kanade_tracker, cv2.COLOR_BGR2BGRA)\n",
    "\t\n",
    "\t# █▀▀ █▀█ █▄ █ █ █ █▀▀ █▀█ ▀█▀   █ █▀▄▀█ █▀▀   ▀█▀ █▀█   █▄▄ █▀▀ █▀█ ▄▀█\n",
    "\t# █▄▄ █▄█ █ ▀█ ▀▄▀ ██▄ █▀▄  █    █ █ ▀ █ █▄█    █  █▄█   █▄█ █▄█ █▀▄ █▀█ to make the merging of windows possible\n",
    "\tframe_lukas_kanade_tracker = cv2.cvtColor(frame_lukas_kanade_tracker, cv2.COLOR_BGR2BGRA) # Lukas-Kanade\n",
    "\tframe_lukas_kanade_goodfeat = cv2.cvtColor(frame_lukas_kanade_goodfeat, cv2.COLOR_BGR2BGRA) # Lukas-Kanade\n",
    "\tframe_canny = cv2.cvtColor(frame_canny, cv2.COLOR_BGR2BGRA) # Canny\n",
    "\n",
    "\t# For No Video Frame Only\n",
    "\tframe_no_video = np.zeros_like(frame_canny)\n",
    "\tframe_no_video[:] = 100\n",
    "\t# print(frame_canny.shape)\n",
    "\thh = int(frame_canny.shape[0] / 2)\n",
    "\tww = int(frame_canny.shape[1] / 2) - (5 * 35)\n",
    "\t\n",
    "\t# █▀█ █   ▄▀█ █▀▀ █▀▀   ▀█▀ █▀▀ ▀▄▀ ▀█▀   █▀▀ █▀█ █▀█   █▀▄ █▀▀ █▀ █▀▀ █▀█ █ █▀█ ▀█▀ █ █▀█ █▄ █\n",
    "\t# █▀▀ █▄▄ █▀█ █▄▄ ██▄    █  ██▄ █ █  █    █▀  █▄█ █▀▄   █▄▀ ██▄ ▄█ █▄▄ █▀▄ █ █▀▀  █  █ █▄█ █ ▀█\n",
    "\tcv2.putText(frame_lukas_kanade_tracker, 'Using: Lukas-Kanade (flow-based feature tracking)', (20, 50), cv2.FONT_HERSHEY_PLAIN, 1, (255, 0, 0), 2)\n",
    "\tcv2.putText(frame_lukas_kanade_goodfeat, 'Using: Lukas-Kanade (flow estimation & good features tracking)', (20, 50), cv2.FONT_HERSHEY_PLAIN, 1, (0, 255, 0), 2)\n",
    "\tcv2.putText(frame_canny, 'Using: Canny (Edge Detection)', (20, 50), cv2.FONT_HERSHEY_PLAIN, 1, (0, 255, 0), 2)\n",
    "\tcv2.putText(frame_no_video, 'NO VIDEO', (ww, hh), cv2.FONT_HERSHEY_PLAIN, 5, (0, 255, 100), 2)\n",
    "\t\n",
    "\t# █▀▀ █▀█ █▀▄▀█ █▄▄ █ █▄ █ █▀▀   █▀▀ █▀█ ▄▀█ █▀▄▀█ █▀▀   ▀█▀ █▀█   █▀█ █▄ █ █▀▀   █ █ █ █ █▄ █ █▀▄ █▀█ █ █ █\n",
    "\t# █▄▄ █▄█ █ ▀ █ █▄█ █ █ ▀█ ██▄   █▀  █▀▄ █▀█ █ ▀ █ ██▄    █  █▄█   █▄█ █ ▀█ ██▄   ▀▄▀▄▀ █ █ ▀█ █▄▀ █▄█ ▀▄▀▄▀\n",
    "\ttop_row = np.concatenate((frame_lukas_kanade_tracker, frame_lukas_kanade_goodfeat), axis=1)\n",
    "\tmiddle_row = np.concatenate((frame_canny, frame_no_video), axis=1)\n",
    "\n",
    "\t# Set the dimensions of the window you want to create\n",
    "\twindow_width = get_screen_size()[0]\n",
    "\twindow_height = get_screen_size()[1]\n",
    "\n",
    "\t# combined_frames = np.concatenate((top_row, middle_row, bottom_row), axis=0)\n",
    "\tcombined_frames = np.concatenate((top_row, middle_row), axis=0)\n",
    "\t\n",
    "\tscaling_factor = min(window_height / combined_frames.shape[1], window_width / combined_frames.shape[0])\n",
    "\th = window_width #int(combined_frames.shape[1] / 1.5) # if using hd camera, divide by 3 instead else 2\n",
    "\tw = window_height #int(combined_frames.shape[0] / 1.5)\n",
    "\tresized_image = cv2.resize(combined_frames, (int(combined_frames.shape[1] * scaling_factor), int(combined_frames.shape[0] * scaling_factor)))\n",
    "\n",
    "\theight, width = resized_image.shape[:2]\n",
    "\t\n",
    "\tx_position = int(abs(width - window_width) / 2)\n",
    "\ty_position = int(abs(height - window_height) / 2) - 30 #int(abs(height - window_height))\n",
    "\n",
    "\t# █▀ █ █ █▀█ █ █ █   █ █ █ █ █▄ █ █▀▄ █▀█ █ █ █\n",
    "\t# ▄█ █▀█ █▄█ ▀▄▀▄▀   ▀▄▀▄▀ █ █ ▀█ █▄▀ █▄█ ▀▄▀▄▀\n",
    "\t# Show Results, \n",
    "\tcv2.imshow('Merged Frames', resized_image)\n",
    "\n",
    "\twindowMoved = False\n",
    "\n",
    "\tif not window_width:\n",
    "\t\tcv2.moveWindow('Merged Frames', x_position, y_position)\n",
    "\t\twindowMoved = True\n",
    "\n",
    "\tif cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "\t\tbreak\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "(16, 157, 86, 238)\n"
     ]
    }
   ],
   "source": [
    "# import cv2 \n",
    "# import numpy as np \n",
    "\n",
    "\n",
    "# # Read image \n",
    "# # image = cv2.imread('./resources/maze/with_obstacle.mp4') \n",
    "# image = cv2.imread('./resources/maze/IMG_20231226_124615.jpg') \n",
    "\n",
    "# # Select ROI \n",
    "# r = cv2.selectROI(\"select the area\", image) \n",
    "\n",
    "# # Crop image \n",
    "# cropped_image = image[int(r[1]):int(r[1]+r[3]), \n",
    "# \t\t\t\t\tint(r[0]):int(r[0]+r[2])] \n",
    "\n",
    "# # Display cropped image \n",
    "# cv2.imshow(\"Cropped image\", cropped_image) \n",
    "# cv2.waitKey(0) \n",
    "# cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def select_roi(video_path):\n",
    "\t# Open the video file\n",
    "\tcap = cv2.VideoCapture(video_path)\n",
    "\n",
    "\t# Read the first frame from the video\n",
    "\tret, frame = cap.read()\n",
    "\n",
    "\t# Display the video to allow the user to select the ROI\n",
    "\tcv2.imshow(\"Select ROI\", frame)\n",
    "\troi = cv2.selectROI(\"Select ROI\", frame, fromCenter=False, showCrosshair=True)\n",
    "\n",
    "\t# while True:\n",
    "\t# \t# Read the next frame from the video\n",
    "\t# \tret, frame = cap.read()\n",
    "\n",
    "\t# \t# If the video has ended, break the loop\n",
    "\t# \tif not ret:\n",
    "\t# \t\tbreak\n",
    "\n",
    "\t# \t# Draw the rectangle on the frame\n",
    "\t# \tcv2.rectangle(frame, (int(roi[0]), int(roi[1])), (int(roi[0] + roi[2]), int(roi[1] + roi[3])), (0, 255, 0), 2)\n",
    "\n",
    "\t# \t# Display the frame with the selected ROI\n",
    "\t# \tcv2.imshow(\"Select ROI\", frame)\n",
    "\n",
    "\t# \t# Break the loop if the user presses the 'Enter' key\n",
    "\t# \tif cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "\t# \t\tbreak\n",
    "\n",
    "\t# Crop the selected ROI from the first frame\n",
    "\t# cropped_roi = frame[int(roi[1]):int(roi[1] + roi[3]), int(roi[0]):int(roi[0] + roi[2])]\n",
    "\t# cropped_roi = int(roi[1]), int(roi[1] + roi[3]), int(roi[0]), int(roi[0] + roi[2])\n",
    "\tcropped_roi = roi\n",
    "\n",
    "\t# Release the video capture object\n",
    "\tcap.release()\n",
    "\n",
    "\t# Close the window\n",
    "\tcv2.destroyAllWindows()\n",
    "\n",
    "\treturn cropped_roi\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\t# Replace 'your_video_path.mp4' with the path to your video file\n",
    "\t# video_path = './resources/maze/with_obstacle.mp4'\n",
    "\t# video_path = './resources/videos/boy-walking.mp4'\n",
    "\tvideo_path = 1\n",
    "\n",
    "\t# Call the function to select and return the ROI as np.array\n",
    "\troi_array = select_roi(video_path)\n",
    "\n",
    "\t# Display the cropped ROI\n",
    "\t# cv2.imshow(\"Cropped ROI\", roi_array)\n",
    "\tprint(roi_array[0])\n",
    "\tprint(roi_array)\n",
    "\tcv2.waitKey(0)\n",
    "\tcv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
